.. _multi-gpu-training:

Distributed and Parallel Training
=================================

Determined provides three main methods to accelerate your model training by
taking advantage of multiple machines and multiple GPUs:

1. **Parallelism across experiments.** Schedule multiple experiments at once:
   more than one experiment can
   proceed in parallel if there are enough machines and GPUS available.
2. **Parallelism within an experiment.** Schedule multiple trials of an experiment at once: a
   :ref:`hyperparameter search <topic-guides_hp-tuning-det>` may run more than
   one trial at once, each of which will use its own GPUs.
3. **Parallelism within a trial.** Use multiple machine to speed up the training of a trial: using
   data parallelism. Determined can coordinate across multiple GPUs on a single machine (parallel training)
   or across multiple GPUs on multiple machines (distributed training) to improve the
   performance of training a single trial.

This how-to will focus on the third approach, demonstrating how to perform distributed or parallel
training with Determined to speed up the training of a single trial.

In the :ref:`experiment-configuration`, the ``resources.slots_per_trial`` option
controls multi-GPU behavior. The default is set to 1 and uses a single GPU to
train a trial.
The ``slots_per_trial`` field indicates the number of GPUs to use to
train a trial. These GPUs may be on a single agent machine or across
multiple machines.

.. note::

      When the ``slots_per_trial`` option is changed, the
      per slot batch size is set to ``global_batch_size`` // ``slots_per_trial``.
      The per slot (gpu) and global batch size should be accessed via the context using
      ``context.get_per_slot_batch_size()`` and ``context.get_global_batch_size()`` respectively.
      If ``global_batch_size`` is not divisible by ``slots_per_trial`` the remainder
      is dropped.


Example configuration with distributed or parallel training:

.. code:: yaml

   resources:
     slots_per_trial: N

To use distributed or parallel training, ``slots_per_trial`` must be set to a multiple
of the GPUs per machine. E.g., if you have a cluster of 8-GPU machines, you need
to set ``slots_per_trial`` to 8, 16, 24, etc. This ensures that the full network
and interconnect bandwidth is available to the multi-GPU workloads and results
in better performance.

.. warning::

  Distributed and parallel training is designed to maximize performance by training with all
  the resources of a machine. This can lead to situations where an experiment is
  created but never becomes active: if the number of GPUs requested does not
  divide into the machines available, for instance, or if another experiment is
  already using some GPUs on a machine.

  If a multi-GPU experiment does not become active after a minute or so,
  please confirm that ``slots_per_trial`` is a multiple of the number of GPUs
  available on a machine. Also, you can also use the CLI command ``det task
  list`` to check if any other tasks are using GPUs and preventing your
  experiment from using all the GPUs on a machine.


Next Steps
----------
- :ref:`optimizing-multi-gpu-training`
